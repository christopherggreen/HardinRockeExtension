\documentclass[11pt]{article}
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}

%\VignetteIndexEntry{Replicating Table 1 of Hardin and Rocke (2005)}
%\VignetteDepends{HardinRockeExtension}
\SweaveOpts{prefix.string=hr, eps=FALSE, pdf=TRUE, strip.white=true}
\SweaveOpts{width=6, height=4.1}

%\usepackage{amsmath}
%\usepackage{amsfonts}% \mathbb
%\usepackage{mathtools}% -> \floor, \ceil
\usepackage[utf8]{inputenc}
%% The following is partly R's share/texmf/Rd.sty
\usepackage{color}
\usepackage{hyperref}
\definecolor{Blue}{rgb}{0,0,0.8}
\definecolor{Red}{rgb}{0.7,0,0}
\hypersetup{%
  hyperindex,%
  colorlinks={true},%
  pagebackref,%
  linktocpage,%
  plainpages={false},%
  linkcolor={Blue},%
  citecolor={Blue},%
  urlcolor={Red},%
  pdfstartview={Fit},%
  pdfview={XYZ null null null}%
}

\usepackage{natbib}
\usepackage[noae]{Sweave}
%----------------------------------------------------
%\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
%\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
%\DeclareMathOperator{\sign}{sign}
%\newcommand{\abs}[1]{\left| #1 \right|}
%\newtheorem{definition}{Definition}
%\newcommand{\byDef}{\mathrm{by\ default}}
%\newcommand{\R}{{\normalfont\textsf{R}}{}}
%\newcommand{\texttt}[1]{\texttt{#1}}
%\newcommand*{\pkg}[1]{\texttt{#1}}
%\newcommand*{\CRANpkg}[1]{\href{http://CRAN.R-project.org/package=#1}{\pkg{#1}}}

%----------------------------------------------------
\begin{document}
%\setkeys{Gin}{width=0.9\textwidth}
%\setlength{\abovecaptionskip}{-5pt}

\title{Replicating Table 1 of Hardin and Rocke (2005)}
\author{Christopher~G. Green}
\maketitle
%\tableofcontents
<<init, echo=FALSE>>=
@

\section{Introduction}
This vignette shows how to use the function
\texttt{hrSimParallel} to replicate Table 1 of
\citet{HardinRocke:2005}, shown on page 942.
We assume the reader can set up a cluster
using the \texttt{parallel} package. 

\section{Setup}
The simulation requires the \texttt{CerioliOutlierDetection}
package as well as the \texttt{parallel} package.
<<setup, eval=FALSE>>=
# Replicate Table 1 in Hardin and Rocke (2005),
# page 942
#
# Christopher G. Green
# 2014-02-24
#
# run simulations in parallel

require( CerioliOutlierDetection )
require( HardinRockeExtension )
require( parallel )
@

Create a cluster using one of the \texttt{makeXXcluster}
functions from the \texttt{parallel} package. On Windows,
\texttt{makePSOCKcluster} is the only available option.
We assume 10 nodes here. \texttt{hrSimParallel} will 
distribute the work within a simulation run across 
the cluster.
<<makecluster, eval=FALSE>>=
thecluster <- makePSOCKcluster(10)
@

Hardin and Rocke used 5000 simulation runs. We set 
a block size of 500 to manage the memory use on our
machine; this will allocate 500 runs to each cluster
node.
<<setsimsize, eval=FALSE>>=
N.SIM <- 5000
B.SIM <- 500
@

Now we initialize each cluster node using
\texttt{clusterEvalQ}. Each node needs a copy
of the two libraries we use for the simulation,
and we create a logfile for each node, tagged
with the process ID of the worker process running
on the node.
<<clusterinit, eval=FALSE>>=
# initialize each node
tmp.rv <- clusterEvalQ( cl = thecluster, {
  require( CerioliOutlierDetection )
  require( HardinRockeExtension )

  my.pid <- Sys.getpid()
  cat("My pid is ", my.pid, "\n")
  logfile <- paste("Test_Old_Method_Parallel_logfile_",my.pid,".txt",sep="")
  cat("Initialized\n\n", file=logfile)

  invisible(NULL)
})
@

Next, we generate the cases we will want to run. Each case
consists of a dimension $p$, a sample size $n$, and an MCD
fraction $\alpha$. Hardin and Rocke used $p \in \{5, 10, 20\}$
and $n \in \{50,100,500,1000\}$, and assumed $\alpha$ was
equal to the maximum breakdown point fraction 
$\frac{\lfloor (n+p+1)/2 \rfloor}{n}$. We run some additional
MCD fractions here for testing purposes.

We chose to order the cases by decreasing sample size so that
the most ``expensive'' cases would run first on our cluster; this
is not required.

Finally, we rotate the matrix of cases to a data frame for use
with lapply and variants (recall that a data frame is a list of
its columns).
<<buildcases, eval=FALSE>>=
# want each case to be a column so that we can use parLapply
hr.cases <- as.matrix(expand.grid(list(p=c(5,10,20),n=c(50,100,500,1000),
  mcd.alpha=c(0.65,0.75,0.85,0.95,0.99))))
hr.cases <- rbind(cbind(hr.cases,FALSE),
  t(apply(as.matrix(expand.grid(list(p=c(5,10,20),n=c(50,100,500,1000)))),
    1,function(x) c(x,mcd.alpha=floor( (x[2] + x[1] + 1)/2 )/x[2],mbp=TRUE) )))
hr.cases <- unique(hr.cases)
hr.cases <- hr.cases[ order(hr.cases[,"mcd.alpha"]),]
hr.cases <- hr.cases[ order(hr.cases[,"n"],decreasing=TRUE),]
dimnames(hr.cases)[[2]] <- c("p","n","mcd.alpha","mbp")
hr.cases <- data.frame(t(hr.cases))
@

Now we run the simulation. We distribute the work of each
case across the cluster. Empirical testing showed that this
was faster on our machines than running entire cases in 
parallel.

Remember to stop your cluster when you're done.
<<runsim, eval=FALSE>>=
cat("Starting run at ", format(Sys.time()), "\n")

hrResults <- lapply(hr.cases, function(pn,clst,ns,bs) {
    cat("Trial p = ",pn[1]," n = ",pn[2],"\n")
    hrSimParallel(cl=clst, p = pn[1] , n = pn[2], 
      mcd.alpha=pn[3], alpha=0.05, N=ns, B=bs, lgf=logfile)
  }, clst=thecluster, ns=N.SIM, bs=B.SIM
)

cat("Run completed at ", format(Sys.time()), "\n")
stopCluster(thecluster)
@

Now we calculate and store the mean and standard deviation
of the results for each case.
<<calcstats, eval=FALSE>>=
allmeans <- as.data.frame(t(rbind( hr.cases, 
  100*sapply( hrResults, function(x) colMeans(x) )
)))
row.names(allmeans) <- NULL

allstds <- as.data.frame(t(rbind( hr.cases, 
  100*sapply( hrResults, function(x) apply(x,2,sd) )
)))
row.names(allstds) <- NULL
@

Finally, we reshape the results for easier comparison
to Table 1 of \cite{HardinRocke:2005}.
<<tabularize, eval=FALSE>>=
# format for easier comparision to hardin and rocke paper
reshape(allmeans[,c("p","n","mcd.alpha","CHI2.CON")  ],
  direction="wide", idvar=c("mcd.alpha","p"),timevar="n")
reshape(allmeans[,c("p","n","mcd.alpha","HRASY.CON") ], 
  direction="wide", idvar=c("mcd.alpha","p"),timevar="n")
reshape(allmeans[,c("p","n","mcd.alpha","HRPRED.CON")], 
  direction="wide", idvar=c("mcd.alpha","p"),timevar="n")

reshape(allstds[,c("p","n","mcd.alpha","CHI2.CON")   ],
  direction="wide", idvar=c("mcd.alpha","p"),timevar="n")
reshape(allstds[,c("p","n","mcd.alpha","HRASY.CON")  ],
  direction="wide", idvar=c("mcd.alpha","p"),timevar="n")
reshape(allstds[,c("p","n","mcd.alpha","HRPRED.CON") ], 
  direction="wide", idvar=c("mcd.alpha","p"),timevar="n")
@

\bibliographystyle{chicago}
\bibliography{hardinrockeextension}
\end{document}
