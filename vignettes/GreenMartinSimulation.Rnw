\documentclass[11pt]{article}
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}

%\VignetteIndexEntry{Extending Hardin and Rocke (2005)---Simulation}
%\VignetteDepends{HardinRockeExtensionSimulations}
\SweaveOpts{prefix.string=hr, eps=FALSE, pdf=TRUE, strip.white=true}
\SweaveOpts{width=6, height=4.1}

%\usepackage{amsmath}
%\usepackage{amsfonts}% \mathbb
%\usepackage{mathtools}% -> \floor, \ceil
\usepackage[utf8]{inputenc}
%% The following is partly R's share/texmf/Rd.sty
\usepackage{color}
\usepackage{hyperref}
\definecolor{Blue}{rgb}{0,0,0.8}
\definecolor{Red}{rgb}{0.7,0,0}
\hypersetup{%
  hyperindex,%
  colorlinks={true},%
  pagebackref,%
  linktocpage,%
  plainpages={false},%
  linkcolor={Blue},%
  citecolor={Blue},%
  urlcolor={Red},%
  pdfstartview={XYZ null null 1},%
  pdfview={XYZ null null null},%
}

\usepackage{natbib}
\usepackage[noae]{Sweave}
%----------------------------------------------------
%\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
%\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
%\DeclareMathOperator{\sign}{sign}
%\newcommand{\abs}[1]{\left| #1 \right|}
%\newtheorem{definition}{Definition}
%\newcommand{\byDef}{\mathrm{by\ default}}
%\newcommand{\R}{{\normalfont\textsf{R}}{}}
%\newcommand{\texttt}[1]{\texttt{#1}}
%\newcommand*{\pkg}[1]{\texttt{#1}}
%\newcommand*{\CRANpkg}[1]{\href{http://CRAN.R-project.org/package=#1}{\pkg{#1}}}

%----------------------------------------------------
\begin{document}
%\setkeys{Gin}{width=0.9\textwidth}
%\setlength{\abovecaptionskip}{-5pt}

\title{Extending Hardin and Rocke (2005)---Simulation Work}
\author{Christopher~G. Green}
\maketitle
%\tableofcontents
<<init, echo=FALSE>>=
@

\section{Introduction}
This vignette shows how to use the function
\texttt{hr.cm} to replicate and extend the 
Monte Carlo simulation performed in 
\cite{HardinRocke:2005} to calculate the 
Wishart degrees of freedom m associated
with the Hardin-Rocke approximation to 
the MCD covariance estimate. \cite{HardinRocke:2005}
calculated this for the maximum breakdown
point case of the MCD, and \cite{GreenMartin:2014a}
extended this to the MCD using an arbitrary
fraction of the data.

We assume the reader can set up a cluster
using the \texttt{parallel} package, but this
is not necessary: one can create a cluster with
a single node.

Note that all code blocks in the vignette are marked
as ``do not evaluate'' to avoid running long simulations
during package checks. In the \texttt{R} code file 
resulting from running \texttt{Stangle} on the vignette
source, you will need to uncomment all the \texttt{R}
code to actually run the simulation.

\section{Setup}
First, we load some required packages and take care of some performance
tuning. The simulation requires the \texttt{CerioliOutlierDetection}
package as well as the \texttt{parallel} package. We also load the
\texttt{RhpcBLASctl} package to force the use of single-threaded BLAS,
if possible: with a multi-threaded BLAS on a multi-core machine, the
cluster ``nodes'' may impede each other. We want each worker to have
the node to itself for maximum efficiency.
<<setup, eval=FALSE>>=
# Christopher G. Green
# 2014-02-24
#
# run simulations in parallel

require( RhpcBLASctl             )
require( parallel                )
require( CerioliOutlierDetection )
require( HardinRockeExtensionSimulations    )

# force single-threaded BLAS if possible
omp_set_num_threads(1)
@

Create a cluster using one of the \texttt{makeXXcluster}
functions from the \texttt{parallel} package. On Windows,
\texttt{makePSOCKcluster} is the only available option.
We assume 10 nodes here. \texttt{hrSimParallel} will 
distribute the work within a simulation run across 
the cluster.

The \texttt{useXDR} option should be set to FALSE
on little endian machines for efficiency.
<<makecluster, eval=FALSE>>=
thecluster <- makePSOCKcluster(10, 
	outfile="gm14_replicate.log", useXDR=FALSE)
@

We initialize the cluster random number generator
with a seed; this makes it possible for you to 
replicate our numbers and the resulting figures.
<<reproduce, eval=FALSE>>=
# make reproducible
clusterSetRNGStream(cl = thecluster, 2014)
@

Now we initialize each cluster node using
\texttt{clusterEvalQ}. Each node needs a copy
of the two libraries we use for the simulation,
and we create a logfile for each node, tagged
with the process ID of the worker process running
on the node.

Hardin and Rocke used 5000 simulation runs. We set 
a block size of 250 to manage the memory use on our
machine; this will allocate 250 runs to each cluster
node.
<<clusterinit, eval=FALSE>>=
# initialize each node
tmp.rv <- clusterEvalQ( cl = thecluster, {
  require( CerioliOutlierDetection )
  require( HardinRockeExtensionSimulations    )
  require( mvtnorm                 )

  N.SIM <- 5000
  B.SIM <- 500

  my.pid <- Sys.getpid()
  cat("My pid is ", my.pid, "\n")
  logfile <- paste("Simulation_AllAlphas_Parallel_logfile_",
    my.pid,".txt",sep="")
  cat("Initialized\n\n", file=logfile)

  invisible(NULL)
})
@

Next, we generate the cases we will want to run. Each case
consists of a dimension $p$, a sample size $n$, and an MCD
fraction $\alpha$. Hardin and Rocke used $p \in \{5, 10, 20\}$
and $n \in \{50,100,500,1000\}$, and assumed $\alpha$ was
equal to the maximum breakdown point fraction 
$\frac{\lfloor (n+p+1)/2 \rfloor}{n}$. We run some additional
dimensions, sample sizes, and MCD fractions here in order to 
expand their model.

We chose to order the cases by decreasing sample size so that
the most ``expensive'' cases would run first on our cluster; this
is not required.

Finally, we rotate the matrix of cases to a data frame for use
with lapply and variants (recall that a data frame is a list of
its columns).
<<buildcases, eval=FALSE>>=
# build the pairs of sample size n and dimension p
hr.cm.params <- expand.grid(
  list(
    p=c(3,5,7,10,15,20),
    n=c(50,100,250,500,750,1000)
  )
)
# adding more coverage for small sample sizes
hr.cm.params <- rbind( hr.cm.params, within( 
  expand.grid(list(p=c(3,5,7,10,15,20), 
    ratio=c( 3,5,7,9,11 ) )), 
  {
    n <- p * ratio
    rm(ratio)
  }
))
# remove any duplicates
hr.cm.params <- unique(hr.cm.params)
# want to run most expensive cases first
hr.cm.params <- hr.cm.params[ order( hr.cm.params$n, 
  hr.cm.params$p, decreasing=TRUE ), ]

# add maximum breakdown point case to the params data set
hr.cm.params[,"mbp"] <- apply( hr.cm.params, 1, 
  function(x) floor( (x[2] + x[1] + 1)/2 )/x[2] )

# want each case to be a column so that we can use parLapply
hr.cm.params <- data.frame(t(as.matrix(hr.cm.params)))
      
mcd.alphas <- c(0.55,0.60,0.65,0.70,0.75,0.80,
  0.85,0.90,0.95,0.99,0.995) 
clusterExport(cl = thecluster, "hr.cm.params")
clusterExport(cl = thecluster, "mcd.alphas")
@

\section{Simulation Runs}
Now we run the simulation. We distribute the work of each
case across the cluster. 

Remember to stop your cluster when you're done.
<<runsim, eval=FALSE>>=
cat("Starting run at ", format(Sys.time()), "\n")

#
# using parLapply here to prevent simplification of the
# results (as parApply would attempt to do)
#
hr.cm.results.all.pre <- parLapply(cl = thecluster, 
  X = hr.cm.params, 
  function(pn) {
    cat("Starting case p = ",pn[1]," n = ",pn[2]," at time ", 
      format(Sys.time()), " \n",file=logfile,append=TRUE)
    results <- hr.cm(p = pn[1] , n = pn[2], N=N.SIM, B=B.SIM, 
      mcd.alpha=unique(c(pn[3],mcd.alphas)), logfile=logfile)
    cat("Finished case p = ",pn[1]," n = ",pn[2]," at time ", 
      format(Sys.time()), " \n",file=logfile,append=TRUE)
    data.frame(p=pn[1],n=pn[2],mbp=pn[3],results)
  }
)
cat("Run completed at ", format(Sys.time()), "\n")

stopCluster(thecluster)

# hr.cm.results.all.pre is a list of data frames
# rbind them all to one big data frame
hr.cm.results.all <- do.call("rbind", hr.cm.results.all.pre )

# remember to save your data!
# save("hr.cm.results.all", file="hr.cm.results.all.final.rda")
@

\section{Analysis of Simulation Results}
In this section we show how to analyze the simulation
results and fit the model presented in \cite{GreenMartin:2014a}.
\subsection{Loading the Data}
We load the data from the simulation runs, add a few
calculations, and sort the data for later use.
<<data-step-01, eval=FALSE>>=
# load the saved data from the simulation
# load("hr.cm.results.all.final.rda")

# some EDA
with( hr.cm.results.all, table(n, p, mcd.alpha) )

# sort by dimension, sample size, mcd.alpha
hr.cm.results.all <- hr.cm.results.all[order(hr.cm.results.all$p,
  hr.cm.results.all$n, hr.cm.results.all$mcd.alpha),]
row.names(hr.cm.results.all) <- NULL

# add the asymptotic c and m estimate
# add asymptotic c and m
hr.cm.results.all <- data.frame(
  hr.cm.results.all,
  t(apply( hr.cm.results.all[,c("n","p","mcd.alpha")], 1,
    function(param) unlist(ch99AsymptoticDF(n.obs=param[1],
      p.dim=param[2],mcd.alpha=param[3]))
  )),
  row.names=NULL
)
names(hr.cm.results.all)[7:8] <- c("c.asy","m.asy")

# this snippet groups all the MBP cases together, and
# ensures that MBP sorts before any of the numeric
# MCD fractions
# also adds the log of the difference between the 
# simulated Wishart deg. of freedom m and the 
# asympotic m
thesorter <- function(x) { n <- length(x); x[c(n,1:(n-1))] }
hr.cm.results.all <- within( hr.cm.results.all, {
      # bin mcd.alpha for plotting
  mcd.alpha.bin <- ifelse( mcd.alpha == mbp, "MBP", 
        format( mcd.alpha, digits=3 ))
      # want MBP to always be first
  mcd.alpha.bin <- factor( mcd.alpha.bin, ordered=TRUE,
    levels=thesorter(sort(unique(mcd.alpha.bin)))  )
  log.sim.asy <- log(m)-log(m.asy)
  rm(mbp)
})
head(hr.cm.results.all)

# check for duplicated results
hr.cm.results.all[duplicated(hr.cm.results.all[,c("n","p","mcd.alpha")]),]
@

\subsection{EDA}
Next we perform some exploratory data analysis via
lattice plots to understand how the simulated $m$ differs from the 
asymptotic $m$, as a function of $n$, $p$, and $\alpha$. For brevity, 
we provide only a few examples.
<<data-step-02a, eval=FALSE, echo=FALSE>>=
require(lattice)
@

\subsubsection{EDA Example 1}
Plot the (logarithm of) simulated Wishart degrees of freedom $m$ against 
sample size $n$ for each dimension $p$ and MCD fraction. 
<<data-step-02b, eval=FALSE>>=
xxx <- xyplot( log(m) ~ n | p, 
        groups = mcd.alpha.bin, 
        data=hr.cm.results.all,
        auto.key=list(space="right",points=TRUE), 
        strip=strip.custom(strip.names=FALSE,strip.levels=TRUE),
    main="Simulated Degrees of Freedom against Sample Size\nBy Alpha and Dimension"
)
trellis.device(windows)
tss <- trellis.par.get("superpose.symbol")
tss$pch <- 1:10
trellis.par.set("superpose.symbol",tss)
print(xxx)
dev.off()
@

\subsubsection{EDA Example 2}
Plot the logarithm of the ratio of the simulated $m$ to the asymptotic $m$ against the
sample size by MCD fraction and dimension. This is Figure 6 in \cite{GreenMartin:2014a}. 
<<data-step-02i, eval=FALSE>>=
xxx <- xyplot( log.sim.asy ~ n | mcd.alpha.bin, 
  groups = p, 
  data=hr.cm.results.all,
  auto.key=list(space="top",points=TRUE,title="DIMENSION",cex=0.6, columns=3), 
  strip=strip.custom(strip.names=FALSE,strip.levels=TRUE),
  main="LOG RATIO OF SIM. DF TO ASY. DF AGAINST SAMPLE SIZE\nBY ALPHA AND DIMENSION",
  scales=list(y=list(relation="free"),x=list(relation="free")),
  panel=function(...) {
    panel.superpose(...)
    panel.abline(h=0, lty="dashed", col="gray")
  },
  xlab="SAMPLE SIZE",
  ylab="LOG RATIO"
)
trellis.device(pdf, file="RatioPlot_LogSimAsy_final.pdf")
tss <- trellis.par.get("superpose.symbol")
tss$pch <- 1:10
trellis.par.set("superpose.symbol",tss)
print(xxx)
dev.off()
@

\subsection{Fitting the model}
Next we fit the model described in \cite{GreenMartin:2014a}
via \texttt{nls}: the EDA suggests that the log of the ratio
of the simulated $m$ to the asymptotic $m$ decreases like 
$c/n^d$, where $d$ is a function of $\alpha$ and $c$ is a function
of $\alpha$ and $p$.
<<data-step-03a, eval=FALSE>>=
nls.final <- nls( log.sim.asy ~ 
  ( b0 + b1*mcd.alpha + b2*p  )/( n^(b4 + b5*mcd.alpha) ),
  data = hr.cm.results.all,
  start = c(b0 = 0, b1 = 1, b2 = 0, b4 = 0, b5 = 1)
)
summary(nls.final)
@

Add the predicted values to the data set.
<<data-step-03b, eval=FALSE>>=
hr.cm.results.all$log.pred.asy <- predict( nls.final, 
  newdata=hr.cm.results.all[,c("mcd.alpha","p","n")] )
hr.cm.results.all <- within(hr.cm.results.all, 
  {
    m.pred <- m.asy * exp(log.pred.asy)
    log.sim.pred <- log(m)-log(m.pred)
  }
)
@

Next we would perform some model diagnostics. 
For example, we can plot the logarithm of the ratio of the value of $m$
predicted by our model versus the asymptotic $m$ against the 
logarithm of the ratio of the simulated $m$ to the asymptotic
$m$ to see how well our predicted values line up with the simulated values. 
The plot is done within each combination of dimension and
MCD fraction. 
<<data-step-03c, eval=FALSE>>=
xxx <- xyplot( log.pred.asy ~ log.sim.asy | p * mcd.alpha.bin,
        data=hr.cm.results.all,
        auto.key=list(space="right",points=TRUE), 
        strip=strip.custom(strip.names=FALSE,strip.levels=TRUE),
    main="Predicted ratio vs observed ratio",
    scales=list(y=list(relation="free"),x=list(relation="free")),
    page=function(n) Sys.sleep(5),
    layout=c(6,3),
    panel=function(...) {
    panel.xyplot(...)
    panel.abline(c(0,1), col="gray", lty="dotted")
    }
)
trellis.device(windows)
tss <- trellis.par.get("superpose.symbol")
tss$pch <- 1:10
trellis.par.set("superpose.symbol",tss)
print(xxx)
dev.off()
@

\subsection{Comparing our model to the Hardin and Rocke model: maximum breakdown point case}
We compare our model's estimates for $m$ in the maximum breakdown point
case against those from the Hardin and Rocke model.
<<data-step-04a, eval=FALSE>>=
# compare our model to HR for alpha = MBP
# hr: log (ratio ) = 0.725 - 0.0063p - 0.078 log(n)
#
hr.compare <- unique(subset( hr.cm.results.all, mcd.alpha.bin == "MBP", 
      select=c("n","p","log.sim.asy","log.pred.asy") ))
hr.compare$log.hr.asy <- apply( hr.compare[,c("n","p")], 1,
  function(x) 0.725 - 0.0063*x[2] - 0.078*log(x[1]))
@

We build a data set to compare the simulated method, the Hardin and
Rocke method, and our method.
<<data-step-04c, eval=FALSE>>=
hr.compare <- reshape( hr.compare, direction="long", 
  varying=list(ratio=c("log.sim.asy","log.pred.asy","log.hr.asy")))
hr.compare$method <- factor( hr.compare$time, labels=c("SIM","CG","HR") )
row.names(hr.compare) <- NULL
hr.compare <- subset( hr.compare, select = c(p, n, log.sim.asy, method) )
names(hr.compare)[3] <- "Ratio"

hr.compare$m.asy <- apply( hr.compare[,c("n","p")], 1, 
  function(x) ch99AsymptoticDF(x[1],x[2])$m.hat.asy )
hr.compare <- within( hr.compare, {
  m <- exp( Ratio ) * m.asy
})
# add in critical values that would come from the estimated df parameters
hr.compare$crit01 <- apply( hr.compare[,c("m","p")], 1, 
  function(x) hr05CriticalValue(x[1],x[2],0.01) )
@

With this data set we can compare the predicted $m$ from each method. For example,
we can plot the value of $m$ versus sample size $n$ for each dimension by
method. 
<<data-step-04d, eval=FALSE>>=
xxx <- xyplot( m ~ n | p,
        groups = method, 
        data=hr.compare,
        strip=strip.custom(strip.names=FALSE,strip.levels=TRUE),
    auto.key=list(space="bottom",points=TRUE, text=c("SIMULATED","PROPOSAL","HR05")), 
    main="PREDICTED DEGREES OF FREEDOM",
    scale=list(x=list(relation="free"),y=list(relation="free")),
    panel=function(...) {
    panel.superpose(...)
    panel.abline(h=0, lty="dotted", col="gray")
    }, 
    pty = "m",
    ylab = "DEGREES OF FREEDOM",
    xlab = "NUMBER OF OBSERVATIONS"
)
trellis.device(windows)
tss <- trellis.par.get("superpose.symbol")
tss$pch <- 1:10
trellis.par.set("superpose.symbol",tss)
print(xxx)
dev.off()
@

\subsection{Comparing our model to the Hardin and Rocke model: non-maximum breakdown point case}
Next we focus on the cases where an MCD fraction other than 
the maximum breakdown point case is used. We compare our model's 
estimates for $m$ in the non-maximum breakdown point case against 
those that would be implied from the Hardin and Rocke model.
<<data-step-05a, eval=FALSE>>=
hr.not05 <- subset(hr.cm.results.all, mcd.alpha.bin != "MBP", 
  c(mcd.alpha,p,n,log.sim.asy,log.pred.asy))
hr.not05$log.hr.asy <- apply( hr.not05[,c("n","p")], 1,
  function(x) 0.725 - 0.0063*x[2] - 0.078*log(x[1]))

hr.not05 <- reshape( hr.not05, direction="long", 
  varying=list(ratio=c("log.sim.asy","log.pred.asy","log.hr.asy")))
hr.not05$method <- factor( hr.not05$time, labels=c("SIM","NEW","HR") )
row.names(hr.not05) <- NULL
hr.not05 <- subset( hr.not05, select = c(mcd.alpha, p, n, log.sim.asy, method) )
names(hr.not05)[4] <- "Ratio"
hr.not05$m.asy <- apply( hr.not05[,c("n","p","mcd.alpha")], 1, 
  function(x) ch99AsymptoticDF(x[1],x[2], x[3])$m.hat.asy )
hr.not05 <- within( hr.not05, {
  m <- exp( Ratio ) * m.asy
})  
# add in critical values that would come from the estimated df parameters
hr.not05$crit01   <- apply( hr.not05[,c("m","p")], 1, 
  function(x) hr05CriticalValue(x[1],x[2],0.01) )
hr.not05$crit05   <- apply( hr.not05[,c("m","p")], 1, 
  function(x) hr05CriticalValue(x[1],x[2],0.05) )
hr.not05$crit025  <- apply( hr.not05[,c("m","p")], 1, 
  function(x) hr05CriticalValue(x[1],x[2],0.025) )
hr.not05$crit001  <- apply( hr.not05[,c("m","p")], 1, 
  function(x) hr05CriticalValue(x[1],x[2],0.001) )
hr.not05$crit0001 <- apply( hr.not05[,c("m","p")], 1, 
  function(x) hr05CriticalValue(x[1],x[2],0.0001) )
@

\subsection{Figures}
Next we generate some figures showing the out-of-sample performance
of our method. For example, here is a plot of the predicted degrees 
of freedom versus sample size by dimension, MCD fraction, and method.
<<data-step-05b, eval=FALSE>>=
xxx <- xyplot( m ~ n | p * mcd.alpha,
        groups = method, 
        data=hr.not05,
        strip=strip.custom(strip.names=FALSE,strip.levels=TRUE),
    auto.key=list(space="bottom",points=TRUE, text=c("SIMULATED","PROPOSAL","HR05")), 
    main="PREDICTED DEGREES OF FREEDOM",
    scale=list(x=list(relation="free"),y=list(relation="free")),
    panel=function(...) {
    panel.superpose(...)
    panel.abline(h=0, lty="dotted", col="gray")
    }, 
    pty = "m",
    ylab = "DEGREES OF FREEDOM",
    xlab = "NUMBER OF OBSERVATIONS",
    layout = c(2,3)
)
trellis.device(windows)
tss <- trellis.par.get("superpose.symbol")
tss$pch <- 1:10
trellis.par.set("superpose.symbol",tss)
print(xxx)
dev.off()
@

Now we look how much the Hardin-Rocke method over- (under-) predicts the value of $m$.
We were particularly concerned with predicting $m$ when 75\% and 95\% of the data is
used in the MCD calculations (for later use in the \cite{Cerioli:2010} tests), so we
break those cases out.
<<data-step-05d, eval=FALSE>>=
# look at ratio of HR05 to simulated
hr.not05.a75 <- reshape( subset(hr.not05, 
  (method %in% c("SIM","HR")) & mcd.alpha == 0.75 ), 
  direction="wide", timevar="method", idvar=c("mcd.alpha","p","n") )
hr.not05.a75 <- within( hr.not05.a75, {
  hr.sim.mratio <- m.HR/m.SIM
      hr.sim.crit01ratio <- crit01.HR/crit01.SIM
})
hr.not05.a95 <- reshape( subset(hr.not05, 
  (method %in% c("SIM","HR")) & mcd.alpha == 0.95 ), 
  direction="wide", timevar="method", idvar=c("mcd.alpha","p","n") )
hr.not05.a95 <- within( hr.not05.a75, {
  hr.sim.mratio <- m.HR/m.SIM
      hr.sim.crit01ratio <- crit01.HR/crit01.SIM
})
@

This code will produce Figure 1 in \cite{GreenMartin:2014a}.
<<data-step-05e, eval=FALSE>>=
xxx <- xyplot( hr.sim.mratio ~ n | p,
  data=hr.not05.a75,
  strip=strip.custom(strip.names=FALSE,strip.levels=TRUE),
  main="DEGREE OF OVERPREDICTION of m\nBY HARDIN-ROCKE METHOD",
  ylim=c(0.97*min(c(1,hr.not05.a75$hr.sim.mratio)),
    1.03*max(hr.not05.a75$hr.sim.mratio)),
  panel=function(...) {
    panel.xyplot(...)
    panel.abline(h=1, lty="dashed", col="black")
  }, 
  pty = "m",
  ylab = "HARDIN-ROCKE m/SIMULATION m",
  xlab = "NUMBER OF OBSERVATIONS",
  layout = c(2,3),
  pch = 19,
  col = "blue"
)
trellis.device(pdf, file="HRvsSimRatioForAlphaNot05_final_a75.pdf")
print(xxx)
dev.off()
@

This code will produce Figure 2 in \cite{GreenMartin:2014a}.
<<data-step-05f, eval=FALSE>>=
xxx <- xyplot( hr.sim.crit01ratio ~ n | p,
  data=hr.not05.a75,
  strip=strip.custom(strip.names=FALSE,strip.levels=TRUE),
  main="DEGREE OF UNDERPREDICTION of 0.01 CRITICAL VALUE\nBY HARDIN-ROCKE METHOD",
  ylim=c(0.97*min(hr.not05.a75$hr.sim.crit01ratio),
    1.03*max(c(1,hr.not05.a75$hr.sim.crit01ratio))),
  panel=function(...) {
    panel.xyplot(...)
    panel.abline(h=1, lty="dashed", col="black")
  }, 
  pty = "m",
  ylab = "HARDIN-ROCKE CRIT./SIMULATION CRIT.",
  xlab = "NUMBER OF OBSERVATIONS",
  layout = c(2,3),
  pch = 19,
  col = "blue"
)
trellis.device(pdf, file="HRvsSimCritRatioForAlphaNot05_final_a75.pdf")
print(xxx)
dev.off()
@


This code will produce Figure 3 in \cite{GreenMartin:2014a}.
<<data-step-05h, eval=FALSE>>=
xxx <- xyplot( hr.sim.mratio ~ n | p,
  data=hr.not05.a95,
  strip=strip.custom(strip.names=FALSE,strip.levels=TRUE),
  main="DEGREE OF OVERPREDICTION of m\nBY HARDIN-ROCKE METHOD",
  ylim=c(0.97*min(c(1,hr.not05.a95$hr.sim.mratio)),
    1.03*max(hr.not05.a95$hr.sim.mratio)),
  panel=function(...) {
    panel.xyplot(...)
    panel.abline(h=1, lty="dashed", col="black")
  }, 
  pty = "m",
  ylab = "HARDIN-ROCKE m/SIMULATION m",
  xlab = "NUMBER OF OBSERVATIONS",
  layout = c(2,3),
  pch = 19,
  col = "blue"
)
trellis.device(pdf, file="HRvsSimRatioForAlphaNot05_final_a95.pdf")
print(xxx)
dev.off()
@

This code will produce Figure 4 in \cite{GreenMartin:2014a}.
<<data-step-05i, eval=FALSE>>=
xxx <- xyplot( hr.sim.crit01ratio ~ n | p,
  data=hr.not05.a95,
  strip=strip.custom(strip.names=FALSE,strip.levels=TRUE),
  main="DEGREE OF UNDERPREDICTION of 0.01 CRITICAL VALUE\nBY HARDIN-ROCKE METHOD",
  ylim=c(0.97*min(hr.not05.a95$hr.sim.crit01ratio),
    1.03*max(c(1,hr.not05.a95$hr.sim.crit01ratio))),
  panel=function(...) {
    panel.xyplot(...)
    panel.abline(h=1, lty="dashed", col="black")
  }, 
  pty = "m",
  ylab = "HARDIN-ROCKE CRIT./SIMULATION CRIT.",
  xlab = "NUMBER OF OBSERVATIONS",
  layout = c(2,3),
  pch = 19,
  col = "blue"
)
trellis.device(pdf, file="HRvsSimCritRatioForAlphaNot05_final_a95.pdf")
print(xxx)
dev.off()
@

We also looked at how well our model works in the maximum breakdown point case. 
<<data-step-05j, eval=FALSE>>=
# check ratio for MBP case
hr.mbp <- subset(hr.cm.results.all, mcd.alpha.bin == "MBP", 
  c(mcd.alpha,p,n,log.sim.asy,log.pred.asy))
hr.mbp$log.hr.asy <- apply( hr.mbp[,c("n","p")], 1,
  function(x) 0.725 - 0.0063*x[2] - 0.078*log(x[1]))

hr.mbp <- reshape( hr.mbp, direction="long", 
  varying=list(ratio=c("log.sim.asy","log.pred.asy","log.hr.asy")))
hr.mbp$method <- factor(hr.mbp$time, labels=c("SIM","NEW","HR") )
row.names(hr.mbp) <- NULL
hr.mbp <- subset( hr.mbp, select = c(mcd.alpha, p, n, log.sim.asy, method) )
names(hr.mbp)[4] <- "Ratio"
hr.mbp$m.asy <- apply( hr.mbp[,c("n","p","mcd.alpha")], 1, 
  function(x) ch99AsymptoticDF(x[1],x[2], x[3])$m.hat.asy )
hr.mbp <- within( hr.mbp, {
  m <- exp( Ratio ) * m.asy
})  
# add in critical values that would come from the estimated df parameters
hr.mbp$crit01   <- apply( hr.mbp[,c("m","p")], 1, 
  function(x) hr05CriticalValue(x[1],x[2],0.01) )
hr.mbp$crit05   <- apply( hr.mbp[,c("m","p")], 1, 
  function(x) hr05CriticalValue(x[1],x[2],0.05) )
hr.mbp$crit025  <- apply( hr.mbp[,c("m","p")], 1, 
  function(x) hr05CriticalValue(x[1],x[2],0.025) )
hr.mbp$crit001  <- apply( hr.mbp[,c("m","p")], 1, 
  function(x) hr05CriticalValue(x[1],x[2],0.001) )
hr.mbp$crit0001 <- apply( hr.mbp[,c("m","p")], 1, 
  function(x) hr05CriticalValue(x[1],x[2],0.0001) )

# look at ratio of HR05 to simulated
hr.mbp.ambp <- reshape( subset(hr.mbp, (method %in% c("SIM","HR")) ), 
  direction="wide", timevar="method", idvar=c("mcd.alpha","p","n") )
hr.mbp.ambp <- within( hr.mbp.ambp, {
  hr.sim.mratio <- m.HR/m.SIM
      hr.sim.crit01ratio <- crit01.HR/crit01.SIM
})
@

Using this data set we can look at various plots comparing the
Hardin-Rocke and Green-Martin approaches as before. For instance,
this code will plot how much the Hardin-Rocke method 
over-(under-)predicts $m$ against sample size, stratified by
dimension.
<<data-step-05k, eval=FALSE>>=
xxx <- xyplot( hr.sim.mratio ~ n | p,
  data=hr.mbp.ambp,
  strip=strip.custom(strip.names=FALSE,strip.levels=TRUE),
  main="DEGREE OF OVERPREDICTION of m\nBY HARDIN-ROCKE METHOD",
  ylim=c(0.97*min(c(1,hr.mbp.ambp$hr.sim.mratio)),
    1.03*max(hr.mbp.ambp$hr.sim.mratio)),
  panel=function(...) {
    panel.xyplot(...)
    panel.abline(h=1, lty="dashed", col="black")
  }, 
  pty = "m",
  ylab = "HARDIN-ROCKE m/SIMULATION m",
  xlab = "NUMBER OF OBSERVATIONS",
  layout = c(2,3),
  pch = 19,
  col = "blue"
)
trellis.device(pdf, file="HRvsSimRatioForMBPCase_final.pdf")
print(xxx)
dev.off()
@

\section{Out of Sample Verification}
We tested our model by re-running the simulation code with 
a different set of parameters, and then testing how well our
model predicted the out of sample simulation results. The 
simulation setup is pretty similar to that used in Section
2.
\subsection{Running the verification code}
<<validate,eval=FALSE>>=
require(parallel)

thecluster <- makePSOCKcluster(10, 
	outfile="hrsim_validate.log", useXDR=FALSE)

# make this reproducible
clusterSetRNGStream(cl = thecluster, 2015)

# initialize each node
tmp.rv <- clusterEvalQ( cl = thecluster, {
  require( CerioliOutlierDetection )
  require( HardinRockeExtensionSimulations )
  N.SIM <- 5000
  B.SIM <- 500
 
  my.pid <- Sys.getpid()
  cat("My pid is ", my.pid, "\n")
  logfile <- paste("Verification_AllAlphas_Parallel_logfile_",my.pid,".txt",sep="")
  cat("Initialized\n\n", file=logfile)

  invisible(NULL)
})

# build the pairs of sample size n and dimension p
hr.cm.params <- expand.grid(
  list( p=c(2,3,5,8,11,16,22),
    n=c(50,150,300,500,750,1000)
  )
)
hr.cm.params <- rbind( hr.cm.params, within( 
  expand.grid(list(p=c(2,3,5,8,11,16,22), 
    ratio=c( 4,6,8,10,12 ) )), 
  {
    n <- p * ratio
    rm(ratio)
  }
))
hr.cm.params <- unique(hr.cm.params)
hr.cm.params <- hr.cm.params[ order( hr.cm.params$n, 
  hr.cm.params$p, decreasing=TRUE ), ]
hr.cm.params[,"mbp"] <- apply( hr.cm.params, 1, 
  function(x) floor( (x[2] + x[1] + 1)/2 )/x[2] )
hr.cm.params <- data.frame(t(as.matrix(hr.cm.params)))
      
mcd.alphas <- c(0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.90,0.95,0.99,0.995,1.00) 
clusterExport(cl = thecluster, "hr.cm.params")
clusterExport(cl = thecluster, "mcd.alphas")

cat("Starting run at ", format(Sys.time()), "\n")

hr.cm.verify.all.pre <- parLapply(cl = thecluster, 
  X = hr.cm.params, function(pn) {
    cat("Starting case p = ",pn[1]," n = ",pn[2]," at time ", 
      format(Sys.time()), " \n",file=logfile,append=TRUE)
    results <- hr.cm(p = pn[1] , n = pn[2], N=N.SIM, B=B.SIM, 
      mcd.alpha=unique(c(pn[3],mcd.alphas)), logfile=logfile)
    cat("Finished case p = ",pn[1]," n = ",pn[2]," at time ", 
      format(Sys.time()), " \n",file=logfile,append=TRUE)
    data.frame(p=pn[1],n=pn[2],mbp=pn[3],results)
  }
)
cat("Run completed at ", format(Sys.time()), "\n")

stopCluster(thecluster)
hr.cm.verify.all <- do.call("rbind", hr.cm.verify.all.pre )
# Save the data for later use
#save("hr.cm.verify.all", file="hr.cm.verify.all.final.rda")
@

\subsection{Loading the Data}
We load the data from the simulation runs, add a few
calculations, and sort the data for later use.
<<data-step06a, eval=FALSE>>=
# load the saved data from the simulation
# load("hr.cm.verify.all.final_v2.rda")

head( hr.cm.verify.all )
row.names(hr.cm.verify.all) <- NULL

hr.cm.verify.all$m.asy <- 
  apply( hr.cm.verify.all[,c("n","p","mcd.alpha")], 1, 
    function(x) ch99AsymptoticDF(x[1],x[2],x[3])$m.hat.asy)

hr.cm.verify.all <- within( hr.cm.verify.all, {
  # bin mcd.alpha for plotting
  mcd.alpha.bin <- ifelse( mcd.alpha == mbp, "MBP", 
    format( mcd.alpha, digits=3 ))
  # want MBP to always be first
  mcd.alpha.bin <- factor( mcd.alpha.bin, ordered=TRUE,
    levels=thesorter(sort(unique(mcd.alpha.bin)))  )
  log.sim.asy <- log(m)-log(m.asy)
})

hr.cm.verify.all[duplicated(hr.cm.verify.all[,c("n","p","mcd.alpha")]),]
hr.cm.verify.all$m.hrnew <- 
  apply( hr.cm.verify.all[,c("n","p","mcd.alpha","m.asy")], 1, 
    function(x) hr05AdjustedDF( x[1], x[2], x[3], x[4], method="GM14" )) 

hr.cm.verify.all$m.hrold <- 
  apply( hr.cm.verify.all[,c("n","p","mcd.alpha","m.asy","mbp")], 1, 
    function(x) if(x[3]==x[5]) 
	  hr05AdjustedDF( x[1], x[2], x[3], x[4], method="HR" ) else NA )

hr.cm.verify.all <- within( hr.cm.verify.all, {
    lsimnew <- log( m ) - log( m.hrnew )
    lsimold <- ifelse( mcd.alpha.bin == "MBP", 
	  log( m ) - log( m.hrold ), NA )
})

# adding noverp variable
hr.cm.verify.all$noverp <- hr.cm.verify.all$n/hr.cm.verify.all$p
hr.cm.verify.all$noverp.cut <- cut( hr.cm.verify.all$noverp, breaks = c(0,5,10,20,Inf) )
levels( hr.cm.verify.all$noverp.cut ) <- c("(0,5]","(5,10]","(10,20]","> 20")
@

\subsection{Figures}
With the verification data set created, we can look at how well our model predicts
the simulated $m$. For example, here is a plot of the logarithm of the ratio of 
the simulated $m$ to the predicted $m$ against sample size, for each MCD fraction 
and ratio $n/\nu$ grouping.
<<data-step06c, eval=FALSE>>=
xxx <- xyplot( lsimnew ~ n | noverp.cut, 
  groups = mcd.alpha.bin, 
  data=hr.cm.verify.all,
  auto.key=list(space="right",points=TRUE), 
  strip=strip.custom(strip.names=FALSE,strip.levels=TRUE),
  main="Log Ratio of Sim. DF to Predicted. DF against Sample Size\nBy Alpha and Dimension",
  scales=list(y=list(relation="free"),x=list(relation="free")),
  panel=function(...) {
    panel.superpose(...)
    panel.abline(h=0, lty="dotted", col="gray")
  }
)
trellis.device(windows)
tss <- trellis.par.get("superpose.symbol")
tss$pch <- 1:10
trellis.par.set("superpose.symbol",tss)
print(xxx)
dev.off()
@

Here is a boxplot of the logarithm of the ratio of the predicted $m$ to the simulated $m$ grouped by 
MCD fraction and ratio $n/\nu$ grouping; this is Figure 7 in \cite{GreenMartin:2014a}.
<<data-step06d, eval=FALSE>>=
xxx <- bwplot( noverp.cut ~ -lsimnew  | mcd.alpha.bin, 
      data=hr.cm.verify.all,
      strip=strip.custom(strip.names=FALSE,strip.levels=TRUE),
  pch = "|",
  panel = function(...) {
    panel.bwplot(...)
    panel.abline(v = 0, lty="dotted")
  },
  ylab = "n/v",
  xlab = "LOG(PREDICTED M/SIMULATED M)",
  main = "",
  horizontal = TRUE
)
trellis.device(pdf, file="Boxplot_Out_of_Sample_Results.pdf")
print(xxx)
dev.off()
@

We can also calculate some statistics on the out-of-sample results, such
as looking at the median of the ratio of the predicted $m$ to the 
simulated $m$, or whether our model has systematic bias for predicting $m$.
<<data-step06e, eval=FALSE>>=
with(hr.cm.verify.all, 
  tapply(-lsimnew,list(noverp.cut,mcd.alpha.bin),median))

# test whether distribution of results tends to be significantly different from 0
# if rejected, the predicted method has some systematic bias
with(hr.cm.verify.all, wilcox.test(m,m.hrnew,paired=TRUE)$p.value )
with(hr.cm.verify.all, wilcox.test(log(m),log(m.hrnew),paired=TRUE)$p.value )
with(hr.cm.verify.all, wilcox.test(-lsimnew))
# sample size for each case
with(hr.cm.verify.all, 
  tapply(-lsimnew,list(noverp.cut,mcd.alpha.bin),length))
with(hr.cm.verify.all, 
  tapply(-lsimnew,list(noverp.cut,mcd.alpha.bin),
    function(x) wilcox.test(x)$p.value < 0.01/52))
with(hr.cm.verify.all, 
  tapply(-lsimnew,list(mcd.alpha.bin),length))
with(hr.cm.verify.all, 
  tapply(-lsimnew,list(mcd.alpha.bin),
    function(x) wilcox.test(x)$p.value < 0.01/13))
@

We list the full out-of-sample performance detail in a table (Table 7 in \cite{GreenMartin:2014a})
for reference. 
<<data-step06g, eval=FALSE>>=
require(Hmisc)
tabledata <- hr.cm.verify.all[,c("p","n","lsimnew","mcd.alpha.bin","noverp.cut")]
tabledata$lsimnew <- -tabledata$lsimnew
tabledata <- tabledata[order(tabledata$noverp.cut,
  tabledata$mcd.alpha.bin,tabledata$p,tabledata$n),]
row.names(tabledata) <- NULL
tabledata <- reshape(tabledata, direction="wide",
  v.names = "lsimnew",
  timevar = "mcd.alpha.bin",
  idvar = c("n","p","noverp.cut")
)
my.caption <- paste("Out of sample performance of the proposed improvement to",
  "the Hardin-Rocke methodology, as measured by the logarithm of the ratio of",
  "the predicted degrees of freedom to the simulated degrees of freedom. The",
  "data in this table is depicted in Figure")
tabledata.latex <- subset(tabledata,select=-c(noverp.cut))
dimnames(tabledata.latex)[[2]] <- gsub("lsimnew\\.","",dimnames(tabledata.latex)[[2]])
row.names(tabledata.latex) <- paste(tabledata.latex$p,
  "\\vphantom{",tabledata.latex$n,"}",sep="")
tabledata.latex <- subset(tabledata.latex,select=-c(p))

zzz <- latex(tabledata.latex, 
      file="HardinRockeOOSResults.tex",
      caption=my.caption, 
  label="Table:HRResults",
  title="",
  cgroup = c("","$\\mcdalpha = $"),
  n.cgroup = c(1,13),
  cdec=c(0,rep(3,13)),
  rgroup = c("$n \\leq 5\\nu$","$5\\nu < n \\leq 10\\nu$",
    "$10\\nu < n \\leq 20\\nu$","$n > 20\\nu$"),
  n.rgroup = tapply(tabledata$noverp.cut,tabledata$noverp.cut,length),
  longtable=TRUE,
  size="footnotesize",
  landscape=TRUE
)
rm(zzz)
@

Next we compare our method's performance to the Hardin-Rocke method in the maximum
breakdown point case. We create a boxplot showing how well each method performs
within four $n/\nu$ sample size bins (Figure 8 in \cite{GreenMartin:2014a}).
<<data-step06h, eval=FALSE>>=
hr.cm.verify.all.aMBP <- rbind(
  structure(data.frame(subset(hr.cm.verify.all, mcd.alpha.bin=="MBP", 
    c(p,n,lsimold)),METHOD="HR05"), names=c("p","n","logratio","METHOD")),
  structure(data.frame(subset(hr.cm.verify.all, mcd.alpha.bin=="MBP", 
    c(p,n,lsimnew)),METHOD="NEW"), names=c("p","n","logratio","METHOD"))
)

hr.cm.verify.all.aMBP$noverp <- hr.cm.verify.all.aMBP$n/hr.cm.verify.all.aMBP$p
hr.cm.verify.all.aMBP$noverp.cut <- cut( hr.cm.verify.all.aMBP$noverp, 
  breaks = c(0,5,10,20,Inf) )
levels( hr.cm.verify.all.aMBP$noverp.cut ) <- c("0 < n/v <= 5","5 < n/v <= 10",
  "10 < n/v <= 20","n/v > 20")

xxx <- bwplot( -logratio ~ METHOD | noverp.cut,
  data = hr.cm.verify.all.aMBP,
  pch = "|",
  panel = function(...) {
    panel.bwplot(...)
    panel.abline(h = 0, lty="dotted")
  },
  xlab = "",
  ylab = "LOG(PREDICTED M/SIMULATED M)",
  main = "",
  scales = list(relation = "same")
)
trellis.device(pdf, file="Boxplot_Me_vs_HR.pdf")
print(xxx)
dev.off()
@

We can formally test whether our model yields significantly different results
than the Hardin-Rocke model. (These test results were reported in Section 3
of \cite{GreenMartin:2014a}.)
<<data-step06m, eval=FALSE>>=
hr.cm.verify.all.aMBP.reshaped <- reshape( 
  subset(hr.cm.verify.all.aMBP, select=c(p,n,noverp.cut,logratio,METHOD)),
  direction="wide",
  v.names="logratio",
  timevar="METHOD",
  idvar=c("p","n","noverp.cut")
)

# these are the Mann-Whitney test stats reported in section 3 of the paper
with(hr.cm.verify.all.aMBP.reshaped, 
  wilcox.test(-logratio.HR05,-logratio.NEW, 
  alternative="two.sided", paired=TRUE, 
  conf.int=TRUE, conf.level=0.99))

by(hr.cm.verify.all.aMBP.reshaped, hr.cm.verify.all.aMBP.reshaped$noverp.cut,
  function(xdf) with(xdf,
  wilcox.test(-logratio.HR05,-logratio.NEW, 
  alternative="two.sided", paired=TRUE, 
  conf.int=TRUE, conf.level=0.99))
)
@

\section{Reference Tables of Simulated $c$ and $m$}
Finally, we tabulate our simulated values of $c$ and $m$ for use by 
other researchers. This is Table 6 in \cite{GreenMartin:2014a}.
<<data-step07a, eval=FALSE>>=
# make a table of all the simulated c and m values
require(Hmisc)
cmtabledata <- hr.cm.results.all[,c("p","n","mcd.alpha","mcd.alpha.bin","m","c")]
# sort by mcd.alpha so that the MBP entry shows up in the right order 
cmtabledata <- cmtabledata[ order(cmtabledata$p,cmtabledata$n,cmtabledata$mcd.alpha), ]
cmtabledata <- cmtabledata[,c("p","n","mcd.alpha.bin","m","c")]
row.names(cmtabledata) <- NULL

# want to split into NC columns each with NN rows
NC <- 2
NN <- 42 # seems to be what we can fit on a page
NP <- ceiling(nrow(cmtabledata)/(NC*NN)) # number of pages
cmindex <- rep(1:NN, NP) + rep( (0:(NP-1)) * (NC*NN), each=NN )

cm.caption <- paste(
  "Wishart degrees of freedom parameter $m_{\\text{sim}}$ and",
  "consistency factor $c_{\\text{sim}}$ determined via",
  "simulation, for various dimensions $\\nu$, sample sizes $n$,",
  "and MCD fractions $\\mcdalpha$.",
  "The abbreviation MBP indicates the maximum breakdown point",
  "fraction $\\mcdalphambp$.",
  sep=" "
)
cmtabledata.latex <- data.frame( cmtabledata[ cmindex, ], " ", 
  cmtabledata[ cmindex + rep(NN,NN*NP), ])

zzz <- latex(cmtabledata.latex, 
  file="TableSimulatedcm.tex",
  caption=cm.caption, 
  label="Table:cmresults",
  title="",
  size="footnotesize",#small",
  cdec=rep(c(0,0,2,rep(3,2),0),NC)[-(6*NC)],
  longtable=TRUE,
  rowname=NULL,
  lines.page=NN,
  colheads = rep(c("$\\nu$","$n$","$\\mcdalpha$","$m_{\\text{sim}}$",
    "$c_{\\text{sim}}$",""), NC)[-(6*NC)],
  col.just = rep(c(rep("r",5),"p{3em}"),NC)[-(6*NC)]
)
rm(zzz)
@

\section{Retesting}
Finally, we test the new method by repeating the
experiment of \cite{HardinRocke:2005}: we simulate
data sets from a multivariate normal and test how
many observations are flagged as outliers. Since the
simulated data sets have no outliers by construction,
the average false positive rate of our method should
be close to the Type 1 error rate $\alpha$.

\subsection{Setup}
We setup a cluster as before, and run \texttt{hrSimParallel}
and \texttt{hrSimNewParallel} for a variety of sample size
and dimension combinations.
<<data-step11a,eval=FALSE>>=
# run simulations in parallel
require( CerioliOutlierDetection )
require( HardinRockeExtensionSimulations )
require( parallel )

thecluster <- makePSOCKcluster(10)

N.SIM <- 5000
B.SIM <- 500

# initialize each node
tmp.rv <- clusterEvalQ( cl = thecluster, {
  require( CerioliOutlierDetection )
  require( HardinRockeExtensionSimulations )

  my.pid <- Sys.getpid()
  cat("My pid is ", my.pid, "\n")
  logfile <- paste("Test_Old_Method_Parallel_logfile_",my.pid,".txt",sep="")
  cat("Initialized\n\n", file=logfile)

  invisible(NULL)
})

hr.cases <- as.matrix(expand.grid(list(p=c(5,10,20),n=c(50,100,500,1000),
  mcd.alpha=c(0.65,0.75,0.85,0.95,0.99))))
hr.cases <- rbind(cbind(hr.cases,FALSE),
  t(apply(as.matrix(expand.grid(list(p=c(5,10,20),n=c(50,100,500,1000)))),
    1,function(x) c(x,mcd.alpha=floor( (x[2] + x[1] + 1)/2 )/x[2],mbp=TRUE) )))
hr.cases <- unique(hr.cases)
hr.cases <- hr.cases[ order(hr.cases[,"mcd.alpha"]),]
hr.cases <- hr.cases[ order(hr.cases[,"n"],decreasing=TRUE),]
dimnames(hr.cases)[[2]] <- c("p","n","mcd.alpha","mbp")
hr.cases <- data.frame(t(hr.cases))

cat("Starting run at ", format(Sys.time()), "\n")

hrResults05.old <- lapply(hr.cases, 
  function(pn,clst,ns,bs) {
    cat("Trial p = ",pn[1]," n = ",pn[2],"\n")
    hrSimParallel(cl=clst, p = pn[1] , n = pn[2], 
      mcd.alpha=pn[3], alpha=0.05, N=ns, B=bs, lgf=logfile)
  }, clst=thecluster, ns=N.SIM, bs=B.SIM
)

cat("Run completed at ", format(Sys.time()), "\n")

cat("Starting run at ", format(Sys.time()), "\n")

hrResults01.old <- lapply(hr.cases, 
  function(pn,clst,ns,bs) {
    cat("Trial p = ",pn[1]," n = ",pn[2],"\n")
    hrSimParallel(cl=clst, p = pn[1] , n = pn[2], 
      mcd.alpha=pn[3], alpha=0.01, N=ns, B=bs, lgf=logfile)
  }, clst=thecluster, ns=N.SIM, bs=B.SIM
)

cat("Run completed at ", format(Sys.time()), "\n")

cat("Starting run at ", format(Sys.time()), "\n")

hrResults05.new <- lapply(hr.cases, 
  function(pn,clst,ns,bs) {
    cat("Trial p = ",pn[1]," n = ",pn[2],"\n")
    hrSimNewParallel(cl=clst, p = pn[1] , n = pn[2], 
      mcd.alpha=pn[3], alpha=0.05, N=ns, B=bs, lgf=logfile)
  }, clst=thecluster, ns=N.SIM, bs=B.SIM
)

cat("Run completed at ", format(Sys.time()), "\n")

cat("Starting run at ", format(Sys.time()), "\n")

hrResults01.new <- lapply(hr.cases, 
  function(pn,clst,ns,bs) {
    cat("Trial p = ",pn[1]," n = ",pn[2],"\n")
    hrSimNewParallel(cl=clst, p = pn[1] , n = pn[2], 
      mcd.alpha=pn[3], alpha=0.01, N=ns, B=bs, lgf=logfile)
  }, clst=thecluster, ns=N.SIM, bs=B.SIM
)

cat("Run completed at ", format(Sys.time()), "\n")

stopCluster(thecluster)
@

\subsection{Calculations}
With the simulation results in hand, we calculate the
average false positive rate and the variability in the
false positive rate.
<<data-step12a,eval=FALSE>>=
# calculate mean false positive rate
allmeans.hrsimnew05 <- as.data.frame(t(rbind( hr.cases, 
  100*sapply( hrResults05.new, function(x) colMeans(x) )
)))
row.names(allmeans.hrsimnew05) <- NULL

allmeans.hrsimnew01 <- as.data.frame(t(rbind( hr.cases, 
  100*sapply( hrResults01.new, function(x) colMeans(x) )
)))
row.names(allmeans.hrsimnew01) <- NULL

allmeans.hrsimold05 <- as.data.frame(t(rbind( hr.cases, 
  100*sapply( hrResults05.old, function(x) colMeans(x) )
)))
row.names(allmeans.hrsimold05) <- NULL

allmeans.hrsimold01 <- as.data.frame(t(rbind( hr.cases, 
  100*sapply( hrResults01.old, function(x) colMeans(x) )
)))
row.names(allmeans.hrsimold01) <- NULL

# calculate std. dev. of false positive rate
allstds.hrsimnew05 <- as.data.frame(t(rbind( hr.cases, 
  100*sapply( hrResults05.new, function(x) apply(x,2,sd) )
)))
row.names(allstds.hrsimnew05) <- NULL

allstds.hrsimnew01 <- as.data.frame(t(rbind( hr.cases, 
  100*sapply( hrResults01.new, function(x) apply(x,2,sd) )
)))
row.names(allstds.hrsimnew01) <- NULL

allstds.hrsimold05 <- as.data.frame(t(rbind( hr.cases, 
  100*sapply( hrResults05.old, function(x) apply(x,2,sd) )
)))
row.names(allstds.hrsimold05) <- NULL

allstds.hrsimold01 <- as.data.frame(t(rbind( hr.cases, 
  100*sapply( hrResults01.old, function(x) apply(x,2,sd) )
)))
row.names(allstds.hrsimold01) <- NULL
@

Next we fix up the results for use in a table.
<<data-step12b,eval=FALSE>>=
names(allmeans.hrsimold01) <- gsub("HR","GM", names(allmeans.hrsimold01))
names(allstds.hrsimold01 ) <- gsub("HR","GM", names(allstds.hrsimold01 ))
names(allmeans.hrsimold05) <- gsub("HR","GM", names(allmeans.hrsimold05))
names(allstds.hrsimold05 ) <- gsub("HR","GM", names(allstds.hrsimold05 ))

allmeans01 <- merge(
  merge(
    allmeans.hrsimnew01[,c("p","n","mcd.alpha","mbp","GMPRED.CON")],
    allstds.hrsimnew01[,c("p","n","mcd.alpha","mbp","GMPRED.CON")],
    by=c("p","n","mcd.alpha","mbp"),
    all=TRUE,
    suffixes=c("MEAN","STD")
  ),
  merge(
    allmeans.hrsimold01[,c("p","n","mcd.alpha","mbp","GMPRED.CON")],
    allstds.hrsimold01[,c("p","n","mcd.alpha","mbp","GMPRED.CON")],
    by=c("p","n","mcd.alpha","mbp"),
    all=TRUE,
    suffixes=c("MEAN","STD")
  ),
  by=c("p","n","mcd.alpha","mbp"),
  all=TRUE,
  suffixes=c("NEW","OLD")
)
allmeans01$mcd.alpha.bin <- ifelse( allmeans01$mbp, "MBP", 
  format( allmeans01$mcd.alpha, 3 ) )
# make ordered factor with MBP first
thesorter <- function(x) { n <- length(x); x[c(n,1:(n-1))] }
allmeans01$mcd.alpha.bin <- factor( allmeans01$mcd.alpha.bin, 
  ordered=TRUE,
  levels=thesorter(sort(unique(allmeans01$mcd.alpha.bin)))  )

# making the table
allmeans01 <- within( allmeans01, {
  # convert to std error
  GMPRED.CONSTDNEW <- GMPRED.CONSTDNEW/sqrt(5000)
  GMPRED.CONSTDOLD <- GMPRED.CONSTDOLD/sqrt(5000)

  NEW <- paste( sprintf("%02.2f", GMPRED.CONMEANNEW), " (", 
    sprintf("%02.2f", GMPRED.CONSTDNEW), ")",sep="" )
  HR05 <- paste( sprintf("%02.2f", GMPRED.CONMEANOLD), " (", 
    sprintf("%02.2f", GMPRED.CONSTDOLD), ")",sep="" )
  n.factor <- factor(n, levels=sort(unique(n)), ordered=TRUE)
  p.factor <- factor(p, levels=sort(unique(p)), ordered=TRUE)
})

allmeans01.reshaped <- reshape( allmeans01[, c("p.factor",
  "n.factor","mcd.alpha.bin","HR05","NEW")], 
  direction="wide", v.names=c("HR05","NEW"), timevar="n.factor",
  idvar=c("p.factor","mcd.alpha.bin")
)

allmeans01.reshaped <- allmeans01.reshaped[ order( allmeans01.reshaped$p.factor, 
  allmeans01.reshaped$mcd.alpha.bin), ]

allmeans01.reshaped <- allmeans01.reshaped[,c("p.factor","mcd.alpha.bin",
  paste(rep(c("HR05","NEW"),4), 
  rep(levels(allmeans01$n.factor),each=2), sep="."))]

allmeans01.reshaped2 <- allmeans01.reshaped[ order(allmeans01.reshaped$mcd.alpha.bin, 
  allmeans01.reshaped$p.factor), ]

######################## 0.05 case #####################################

allmeans05 <- merge(
  merge(
    allmeans.hrsimnew05[,c("p","n","mcd.alpha","mbp","GMPRED.CON")],
    allstds.hrsimnew05[,c("p","n","mcd.alpha","mbp","GMPRED.CON")],
    by=c("p","n","mcd.alpha","mbp"),
    all=TRUE,
    suffixes=c("MEAN","STD")
  ),
  merge(
    allmeans.hrsimold05[,c("p","n","mcd.alpha","mbp","GMPRED.CON")],
    allstds.hrsimold05[,c("p","n","mcd.alpha","mbp","GMPRED.CON")],
    by=c("p","n","mcd.alpha","mbp"),
    all=TRUE,
    suffixes=c("MEAN","STD")
  ),
  by=c("p","n","mcd.alpha","mbp"),
  all=TRUE,
  suffixes=c("NEW","OLD")
)
allmeans05$mcd.alpha.bin <- ifelse( allmeans05$mbp, "MBP", 
  format( allmeans05$mcd.alpha, 3 ) )
# make ordered factor with MBP first
thesorter <- function(x) { n <- length(x); x[c(n,1:(n-1))] }
allmeans05$mcd.alpha.bin <- factor( allmeans05$mcd.alpha.bin, 
  ordered=TRUE,
  levels=thesorter(sort(unique(allmeans05$mcd.alpha.bin)))  )

# making the table
allmeans05 <- within( allmeans05, {
  # convert to std error
  GMPRED.CONSTDNEW <- GMPRED.CONSTDNEW/sqrt(5000)
  GMPRED.CONSTDOLD <- GMPRED.CONSTDOLD/sqrt(5000)

  NEW <- paste( sprintf("%02.2f", GMPRED.CONMEANNEW), " (", 
    sprintf("%02.2f", GMPRED.CONSTDNEW), ")",sep="" )
  HR05 <- paste( sprintf("%02.2f", GMPRED.CONMEANOLD), " (", 
    sprintf("%02.2f", GMPRED.CONSTDOLD), ")",sep="" )
  n.factor <- factor(n, levels=sort(unique(n)), ordered=TRUE)
  p.factor <- factor(p, levels=sort(unique(p)), ordered=TRUE)
})

allmeans05.reshaped <- reshape( allmeans05[, c("p.factor","n.factor",
  "mcd.alpha.bin","HR05","NEW")], 
  direction="wide", v.names=c("HR05","NEW"), timevar="n.factor",
  idvar=c("p.factor","mcd.alpha.bin")
)

allmeans05.reshaped <- allmeans05.reshaped[ order( allmeans05.reshaped$p.factor, 
  allmeans05.reshaped$mcd.alpha.bin), ]

allmeans05.reshaped <- allmeans05.reshaped[,c("p.factor","mcd.alpha.bin",
  paste(rep(c("HR05","NEW"),4),rep(levels(allmeans05$n.factor),each=2), sep="."))]

allmeans05.reshaped2 <- allmeans05.reshaped[ order(allmeans05.reshaped$mcd.alpha.bin, 
  allmeans05.reshaped$p.factor), ]
@

Finally, we create Tables 1 and 2 of \cite{GreenMartin:2014a} depicting the results of 
testing our method's false positive rate.
<<data-step12a,eval=FALSE>>=
require(Hmisc)

mycaption <- paste("Mean percentage of simulated data, for selected",
  "sample sizes $n$ and dimensions $\\nu$, with",
  "MCD$(\\mcdalpha)$-based Mahalanobis distances exceeding the",
  "0.01 quantile produced using the",
  "Hardin-Rocke method (HR05) and the proposed correction method (NEW). Ideally,",
  "each percentage should be close to 1\\%.",
  "Standard errors are given in parentheses and are also expressed in percentages.",
  "Compare to Table 2 of",
  "\\cite{HardinRocke:2005}, which showed the results",
  "results of using their method in the maximum breakdown point case (MBP) of MCD."
)
zzz <- latex( allmeans01.reshaped2[ , c(3:10)],
  file="allmeans01.reshaped2.tex",
  caption=mycaption,
  label="Table:HardinRockeTable2:01",
  title="",
  cgroup=c(paste("n =", levels( allmeans01$n.factor) )),
  n.cgroup=c(2,2,2,2),
  colheads=c(rep(c("HR05","NEW"),4)),
  rowname=allmeans01.reshaped2$p.factor,
  rowlabel="Dimension ($\\nu$)",
  cdec=c(rep(3,8)),
  rgroup=paste("\\mcdalpha =",levels( allmeans01.reshaped2$mcd.alpha.bin )),
  n.rgroup=with( allmeans01.reshaped2, tapply( p.factor, mcd.alpha.bin, length)),
  #longtable=TRUE,
  size="small",
  landscape=TRUE#,
  #rowname=NULL
)


mycaption <- paste("Mean percentage of simulated data, for selected sample sizes",
  "$n$ and dimensions $\\nu$, with MCD$(\\mcdalpha)$-based Mahalanobis distances",
  "exceeding the 0.05 quantile produced using the Hardin-Rocke method (HR05) and",
  "the proposed correction method (NEW). Ideally, each percentage should be close",
  "to 5\\%. Standard errors are given in parentheses and are also expressed in",
  "percentages. Compare to Table 1 of \\cite{HardinRocke:2005}, which showed the results",
  "results of using their method in the maximum breakdown point case (MBP) of MCD."
)

zzz <- latex( allmeans05.reshaped2[ , c(3:10)],
  file="allmeans05.reshaped2.tex",
  caption=mycaption,
  label="Table:HardinRockeTable2:05",
  title="",
  cgroup=c(paste("n =", levels( allmeans05$n.factor) )),
  n.cgroup=c(2,2,2,2),
  colheads=c(rep(c("HR05","NEW"),4)),
  rowname=allmeans05.reshaped2$p.factor,
  rowlabel="Dimension ($\\nu$)",
  cdec=c(rep(3,8)),
  rgroup=paste("\\mcdalpha =",levels( allmeans05.reshaped2$mcd.alpha.bin )),
  n.rgroup=with( allmeans05.reshaped2, tapply( p.factor, mcd.alpha.bin, length)),
  #longtable=TRUE,
  size="small",
  landscape=TRUE#,
  #rowname=NULL
)
@


\bibliographystyle{plainnat}
\bibliography{HardinRockeExtensionSimulations}
\end{document}
